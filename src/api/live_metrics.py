"""
Live Metrics API Router
ì‹¤ì‹œê°„ íŠ¸ë˜í”½ ë° ë©”íŠ¸ë¦­ ìŠ¤íŠ¸ë¦¬ë° (Container App Logs ê¸°ë°˜)
"""
import asyncio
import json
import logging
import re
from collections import deque
from datetime import datetime, timedelta
from typing import Any, Dict, List

from fastapi import APIRouter, WebSocket, WebSocketDisconnect
from pydantic import BaseModel

from ..config import get_settings

logger = logging.getLogger(__name__)
router = APIRouter(prefix="/api/live-metrics", tags=["live-metrics"])

settings = get_settings()


class MetricData(BaseModel):
    """ë©”íŠ¸ë¦­ ë°ì´í„°"""
    timestamp: str
    request_count: int
    avg_duration: float
    error_count: int
    success_rate: float


class ConnectionManager:
    """WebSocket ì—°ê²° ê´€ë¦¬ì"""
    
    def __init__(self):
        self.active_connections: List[WebSocket] = []
        self.metrics_buffer = deque(maxlen=60)  # ìµœê·¼ 60ì´ˆ ë°ì´í„°
        self.current_minute_requests: List[Dict[str, Any]] = []
        self.last_reset = datetime.utcnow()
        self._loop = None
        self.use_dummy_logs = True  # ê¸°ë³¸ê°’: ë”ë¯¸ ë¡œê·¸ ì‚¬ìš©
    
    def set_event_loop(self, loop):
        """ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •"""
        self._loop = loop
    
    async def connect(self, websocket: WebSocket):
        await websocket.accept()
        self.active_connections.append(websocket)
        logger.info(f"WebSocket ì—°ê²°ë¨. ì´ ì—°ê²° ìˆ˜: {len(self.active_connections)}")
    
    def disconnect(self, websocket: WebSocket):
        if websocket in self.active_connections:
            self.active_connections.remove(websocket)
        logger.info(f"WebSocket ì—°ê²° í•´ì œë¨. ì´ ì—°ê²° ìˆ˜: {len(self.active_connections)}")
    
    async def broadcast(self, message: dict):
        """ëª¨ë“  ì—°ê²°ëœ í´ë¼ì´ì–¸íŠ¸ì— ë©”ì‹œì§€ ì „ì†¡"""
        disconnected = []
        for connection in self.active_connections:
            try:
                await connection.send_json(message)
            except Exception as e:
                logger.error(f"ë©”ì‹œì§€ ì „ì†¡ ì‹¤íŒ¨: {e}")
                disconnected.append(connection)
        
        # ì—°ê²° í•´ì œëœ í´ë¼ì´ì–¸íŠ¸ ì œê±°
        for conn in disconnected:
            self.disconnect(conn)
    
    async def add_request_log_async(self, log_data: Dict[str, Any]):
        """ìš”ì²­ ë¡œê·¸ ì¶”ê°€ ë° ê°œë³„ ìš”ì²­ ë¸Œë¡œë“œìºìŠ¤íŠ¸ (ë¹„ë™ê¸°)"""
        self.current_minute_requests.append(log_data)
        
        # ê°œë³„ ìš”ì²­ ì´ë²¤íŠ¸ ì¦‰ì‹œ ë¸Œë¡œë“œìºìŠ¤íŠ¸
        if self.active_connections:
            logger.debug(f"ğŸ“¡ ë¸Œë¡œë“œìºìŠ¤íŒ… new_request to {len(self.active_connections)} clients: {log_data['method']} {log_data['path']}")
            await self.broadcast({
                "type": "new_request",
                "data": log_data
            })
        else:
            logger.warning("âš ï¸ í™œì„± ì—°ê²°ì´ ì—†ì–´ ë¸Œë¡œë“œìºìŠ¤íŠ¸ ê±´ë„ˆëœ€")
    
    def add_request_log(self, log_data: Dict[str, Any]):
        """ìš”ì²­ ë¡œê·¸ ì¶”ê°€ (ë™ê¸° ë˜í¼)"""
        self.current_minute_requests.append(log_data)
        
        # ë¹„ë™ê¸° ë¸Œë¡œë“œìºìŠ¤íŠ¸ë¥¼ ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰
        if self.active_connections and self._loop:
            asyncio.run_coroutine_threadsafe(
                self.broadcast({
                    "type": "new_request",
                    "data": log_data
                }),
                self._loop
            )
    
    def calculate_metrics(self) -> MetricData:
        """í˜„ì¬ ë¶„ì˜ ë©”íŠ¸ë¦­ ê³„ì‚°"""
        if not self.current_minute_requests:
            return MetricData(
                timestamp=datetime.utcnow().isoformat(),
                request_count=0,
                avg_duration=0,
                error_count=0,
                success_rate=100.0
            )
        
        total_requests = len(self.current_minute_requests)
        total_duration = sum(req.get('duration', 0) for req in self.current_minute_requests)
        error_count = sum(1 for req in self.current_minute_requests if req.get('status_code', 200) >= 400)
        success_count = total_requests - error_count
        
        return MetricData(
            timestamp=datetime.utcnow().isoformat(),
            request_count=total_requests,
            avg_duration=total_duration / total_requests if total_requests > 0 else 0,
            error_count=error_count,
            success_rate=(success_count / total_requests * 100) if total_requests > 0 else 100.0
        )
    
    def reset_minute_buffer(self):
        """ë¶„ ë‹¨ìœ„ ë²„í¼ ë¦¬ì…‹"""
        self.current_minute_requests.clear()
        self.last_reset = datetime.utcnow()


manager = ConnectionManager()


def parse_container_log(log_line: str) -> Dict[str, Any] | None:
    """
    Container App ë¡œê·¸ íŒŒì‹±
    FastAPI ë¡œê·¸ í˜•ì‹: INFO:     127.0.0.1:12345 - "GET /api/etf/list HTTP/1.1" 200 OK
    """
    try:
        # FastAPI/Uvicorn ë¡œê·¸ íŒ¨í„´
        # ì˜ˆ: INFO:     127.0.0.1:12345 - "GET /api/etf/list HTTP/1.1" 200 OK
        pattern = r'(?P<level>\w+):\s+(?P<client>[\d\.:]+)\s+-\s+"(?P<method>\w+)\s+(?P<path>[^\s]+)\s+HTTP/[\d\.]+"\s+(?P<status>\d+)'
        match = re.search(pattern, log_line)
        
        if match:
            return {
                'timestamp': datetime.utcnow().isoformat(),
                'method': match.group('method'),
                'path': match.group('path'),
                'status_code': int(match.group('status')),
                'duration': 0,  # ë¡œê·¸ì—ì„œ ì¶”ì¶œ ë¶ˆê°€, ê¸°ë³¸ê°’
            }
        
        # Application Insights í˜•ì‹ ë¡œê·¸ (duration í¬í•¨)
        # ì˜ˆ: {"timestamp": "...", "duration": 123, "resultCode": 200}
        if '{' in log_line and '}' in log_line:
            try:
                json_match = re.search(r'\{.*\}', log_line)
                if json_match:
                    data = json.loads(json_match.group())
                    if 'resultCode' in data or 'status' in data:
                        return {
                            'timestamp': data.get('timestamp', datetime.utcnow().isoformat()),
                            'method': data.get('method', 'GET'),
                            'path': data.get('url', '/'),
                            'status_code': data.get('resultCode', data.get('status', 200)),
                            'duration': data.get('duration', 0),
                        }
            except json.JSONDecodeError:
                pass
        
        return None
    except Exception as e:
        logger.debug(f"ë¡œê·¸ íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None


async def stream_container_logs():
    """
    Container App ì‹¤ì‹œê°„ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°
    Production í™˜ê²½ì—ì„œëŠ” ë¯¸ë“¤ì›¨ì–´ê°€ ì‹¤ì œ íŠ¸ë˜í”½ì„ ì „ì†¡í•˜ë¯€ë¡œ ë”ë¯¸ ë¡œê·¸ ë¶ˆí•„ìš”
    """
    import os
    import shutil

    # í† ê¸€ ìƒíƒœ í™•ì¸: Falseë©´ ë”ë¯¸ ë¡œê·¸ ìƒì„± ì•ˆ í•¨
    if not manager.use_dummy_logs:
        logger.info("âœ… ì‹¤ì œ íŠ¸ë˜í”½ ëª¨ë“œ: ë¯¸ë“¤ì›¨ì–´ì—ì„œ HTTP ìš”ì²­ì„ Live Metricsì— ì „ì†¡í•©ë‹ˆë‹¤.")
        # ë¬´í•œ ëŒ€ê¸° (ë”ë¯¸ ë¡œê·¸ ìƒì„± ì•ˆ í•¨)
        while True:
            await asyncio.sleep(60)
        return
    
    # ë”ë¯¸ ë¡œê·¸ ëª¨ë“œ
    logger.warning(f"ğŸ² ë”ë¯¸ ë¡œê·¸ ëª¨ë“œ í™œì„±í™” (environment={settings.environment})")
    
    container_app_name = os.getenv("CONTAINER_APP_NAME", "ca-sk-appinsights")
    resource_group = os.getenv("RESOURCE_GROUP", "rg-sk-appinsights")
    
    # Azure CLI ì„¤ì¹˜ í™•ì¸
    if not shutil.which("az"):
        logger.warning("Azure CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„° ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
        await stream_dummy_logs()
        return
    
    try:
        # az containerapp logs show --name <name> --resource-group <rg> --follow --tail 0
        cmd = [
            "az", "containerapp", "logs", "show",
            "--name", container_app_name,
            "--resource-group", resource_group,
            "--follow",
            "--tail", "0"
        ]
        
        logger.info(f"Container App ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘: {container_app_name}")
        
        # asyncio subprocess ì‚¬ìš©
        process = await asyncio.create_subprocess_exec(
            *cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE
        )
        
        # stdoutê°€ Noneì´ ì•„ë‹Œì§€ í™•ì¸
        if process.stdout is None:
            logger.error("í”„ë¡œì„¸ìŠ¤ stdoutì´ Noneì…ë‹ˆë‹¤.")
            await stream_dummy_logs()
            return
        
        # ë¡œê·¸ ì½ê¸° ë£¨í”„
        while True:
            line = await process.stdout.readline()
            if not line:
                break
            
            # ë¡œê·¸ íŒŒì‹±
            log_line = line.decode('utf-8').strip()
            log_data = parse_container_log(log_line)
            if log_data:
                manager.add_request_log(log_data)
            
    except FileNotFoundError:
        logger.error("Azure CLIê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
        # ë”ë¯¸ ë°ì´í„° ìƒì„± ëª¨ë“œ
        await stream_dummy_logs()
    except Exception as e:
        logger.error(f"ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì˜¤ë¥˜: {e}", exc_info=True)
        await stream_dummy_logs()


async def stream_dummy_logs():
    """
    ê°œë°œ ëª¨ë“œ: ë”ë¯¸ ë¡œê·¸ ìƒì„±
    """
    import random
    
    logger.info("ğŸ² ë”ë¯¸ ë¡œê·¸ ìƒì„± ëª¨ë“œ ì‹œì‘!")
    
    while True:
        try:
            # í† ê¸€ì´ êº¼ì§€ë©´ ì¢…ë£Œ
            if not manager.use_dummy_logs:
                logger.info("ğŸ›‘ ë”ë¯¸ ë¡œê·¸ ìƒì„± ì¤‘ë‹¨ (í† ê¸€ ë¹„í™œì„±í™”)")
                break
            
            # ì´ˆë‹¹ 1-3ê°œì˜ ë”ë¯¸ ìš”ì²­ ìƒì„± (CPU ì ˆì•½)
            num_requests = random.randint(1, 3)
            logger.info(f"ğŸ”„ {num_requests}ê°œ ë”ë¯¸ ìš”ì²­ ìƒì„± ì¤‘...")
            
            for _ in range(num_requests):
                log_data = {
                    'timestamp': datetime.utcnow().isoformat(),
                    'method': random.choice(['GET', 'POST', 'PUT', 'DELETE']),
                    'path': random.choice(['/api/etf/list', '/api/stocks/AAPL', '/api/chat/', '/api/news/market']),
                    'status_code': random.choices([200, 201, 400, 404, 500], weights=[85, 5, 5, 3, 2])[0],
                    'duration': random.uniform(10, 300),
                }
                logger.debug(f"ğŸ“¤ ë”ë¯¸ ìš”ì²­ ìƒì„±: {log_data['method']} {log_data['path']} - {log_data['status_code']}")
                await manager.add_request_log_async(log_data)
            
            await asyncio.sleep(1.5)  # 1ì´ˆ â†’ 1.5ì´ˆë¡œ ì¦ê°€
        except Exception as e:
            logger.error(f"ë”ë¯¸ ë¡œê·¸ ìƒì„± ì˜¤ë¥˜: {e}", exc_info=True)
            await asyncio.sleep(1)


# ë°±ê·¸ë¼ìš´ë“œ ì‘ì—…: ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë°
log_streaming_task = None
log_streaming_started = False


async def start_log_streaming():
    """ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
    global log_streaming_task, log_streaming_started
    
    if not log_streaming_started:
        log_streaming_started = True
        logger.info("ğŸš€ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì¤‘...")
        log_streaming_task = asyncio.create_task(stream_container_logs())
        logger.info("âœ… ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° íƒœìŠ¤í¬ ìƒì„± ì™„ë£Œ")


async def metrics_aggregation_loop():
    """
    1ì´ˆë§ˆë‹¤ ë©”íŠ¸ë¦­ ê³„ì‚° ë° ë¸Œë¡œë“œìºìŠ¤íŠ¸
    """
    while True:
        try:
            # ë©”íŠ¸ë¦­ ê³„ì‚°
            metrics = manager.calculate_metrics()
            
            # í´ë¼ì´ì–¸íŠ¸ì— ë¸Œë¡œë“œìºìŠ¤íŠ¸
            await manager.broadcast({
                "type": "traffic_update",
                "data": metrics.model_dump()
            })
            
            # 1ë¶„ë§ˆë‹¤ ë²„í¼ ë¦¬ì…‹
            if (datetime.utcnow() - manager.last_reset).total_seconds() >= 60:
                manager.reset_minute_buffer()
            
            await asyncio.sleep(1)
            
        except Exception as e:
            logger.error(f"ë©”íŠ¸ë¦­ ì§‘ê³„ ì˜¤ë¥˜: {e}", exc_info=True)
            await asyncio.sleep(1)


@router.websocket("/ws/traffic")
async def websocket_traffic(websocket: WebSocket):
    """
    ì‹¤ì‹œê°„ íŠ¸ë˜í”½ ë°ì´í„° ìŠ¤íŠ¸ë¦¬ë° WebSocket
    Container App ë¡œê·¸ ê¸°ë°˜ ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­
    """
    logger.info("ğŸ”Œ ìƒˆë¡œìš´ WebSocket ì—°ê²° ìš”ì²­")
    await manager.connect(websocket)
    
    # ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì •
    manager.set_event_loop(asyncio.get_event_loop())
    logger.info("âš™ï¸ ì´ë²¤íŠ¸ ë£¨í”„ ì„¤ì • ì™„ë£Œ")
    
    # ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    logger.info("ğŸš€ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ í˜¸ì¶œ...")
    await start_log_streaming()
    logger.info("âœ… ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘ ì™„ë£Œ")
    
    # ë©”íŠ¸ë¦­ ì§‘ê³„ íƒœìŠ¤í¬ ì‹œì‘
    aggregation_task = asyncio.create_task(metrics_aggregation_loop())
    logger.info("ğŸ“Š ë©”íŠ¸ë¦­ ì§‘ê³„ íƒœìŠ¤í¬ ì‹œì‘")
    
    try:
        # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ëŒ€ê¸° (ì—°ê²° ìœ ì§€)
        while True:
            try:
                await websocket.receive_text()
            except WebSocketDisconnect:
                break
            await asyncio.sleep(0.1)
                
    except WebSocketDisconnect:
        manager.disconnect(websocket)
        logger.info("í´ë¼ì´ì–¸íŠ¸ ì—°ê²° í•´ì œ")
    except Exception as e:
        logger.error(f"WebSocket ì˜¤ë¥˜: {e}", exc_info=True)
        manager.disconnect(websocket)
    finally:
        # ì§‘ê³„ íƒœìŠ¤í¬ ì·¨ì†Œ
        aggregation_task.cancel()
        logger.info("ğŸ›‘ ë©”íŠ¸ë¦­ ì§‘ê³„ íƒœìŠ¤í¬ ì¢…ë£Œ")


@router.get("/current")
async def get_current_metrics():
    """
    í˜„ì¬ ë©”íŠ¸ë¦­ ì¡°íšŒ (REST API)
    """
    metrics = manager.calculate_metrics()
    return metrics


@router.get("/history")
async def get_metrics_history(minutes: int = 60):
    """
    ê³¼ê±° ë©”íŠ¸ë¦­ ì¡°íšŒ (ë”ë¯¸ ë°ì´í„°)
    
    - **minutes**: ì¡°íšŒí•  ì‹œê°„ ë²”ìœ„ (ë¶„)
    """
    import random

    # ë”ë¯¸ íˆìŠ¤í† ë¦¬ ë°ì´í„° ìƒì„±
    history = []
    for i in range(min(minutes, 60)):
        timestamp = datetime.utcnow() - timedelta(minutes=minutes-i)
        history.append({
            "timestamp": timestamp.isoformat(),
            "request_count": random.randint(5, 50),
            "avg_duration": random.uniform(50, 200),
            "error_count": random.randint(0, 5),
            "success_rate": random.uniform(90, 100)
        })
    
    return {"history": history}


@router.post("/toggle-dummy-logs")
async def toggle_dummy_logs(enabled: bool):
    """
    ë”ë¯¸ ë¡œê·¸ ìƒì„± í† ê¸€
    
    - **enabled**: Trueì´ë©´ ë”ë¯¸ ë¡œê·¸ ì‚¬ìš©, Falseë©´ ì‹¤ì œ ë°ì´í„° ì‚¬ìš©
    """
    manager.use_dummy_logs = enabled
    
    # ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì¬ì‹œì‘ì´ í•„ìš”í•œ ê²½ìš°
    global log_streaming_task, log_streaming_started
    if log_streaming_task and not log_streaming_task.done():
        log_streaming_task.cancel()
        log_streaming_started = False
    
    # í™œì„±í™”ëœ ê²½ìš° ìƒˆë¡œìš´ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘
    if enabled:
        await start_log_streaming()
    
    return {
        "success": True,
        "use_dummy_logs": manager.use_dummy_logs,
        "environment": settings.environment,
        "message": f"ë”ë¯¸ ë¡œê·¸ ëª¨ë“œ: {'í™œì„±í™”' if enabled else 'ë¹„í™œì„±í™”'}"
    }


@router.get("/dummy-logs-status")
async def get_dummy_logs_status():
    """
    ë”ë¯¸ ë¡œê·¸ ìƒì„± ìƒíƒœ ì¡°íšŒ
    """
    return {
        "use_dummy_logs": manager.use_dummy_logs,
        "environment": settings.environment,
        "is_production": settings.environment.lower() == "production"
    }


@router.on_event("startup")
async def startup_event():
    """ì•± ì‹œì‘ ì‹œ ë¡œê·¸ ìŠ¤íŠ¸ë¦¬ë° ì‹œì‘"""
    logger.info("ğŸ¯ Live Metrics ì„œë¹„ìŠ¤ ì‹œì‘")
    # í™˜ê²½ì— ë”°ë¼ ì´ˆê¸° í† ê¸€ ìƒíƒœ ì„¤ì •
    # productionì—ì„œëŠ” ì‹¤ì œ íŠ¸ë˜í”½ë§Œ ì‚¬ìš© (ë”ë¯¸ ë¡œê·¸ ë¹„í™œì„±í™”)
    manager.use_dummy_logs = settings.environment.lower() != "production"
    logger.info(f"ì´ˆê¸° ë”ë¯¸ ë¡œê·¸ ìƒíƒœ: {manager.use_dummy_logs} (environment: {settings.environment})")
    logger.info("âœ… Production: ì‹¤ì œ HTTP íŠ¸ë˜í”½ì´ ë¯¸ë“¤ì›¨ì–´ë¥¼ í†µí•´ Live Metricsì— ì „ì†¡ë©ë‹ˆë‹¤.")
    # WebSocket ì—°ê²° ì‹œ ì‹œì‘ë˜ë„ë¡ ë³€ê²½ (startupì—ì„œëŠ” ì‹œì‘í•˜ì§€ ì•ŠìŒ)
